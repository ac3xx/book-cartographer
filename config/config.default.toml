# EPUB Character Graph Generator - Sample Configuration File
# Copy this file to config.toml and customize as needed

# Logging and general configuration
log_level = "DEBUG"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
save_interim_data = true  # Whether to save interim processing data
interim_data_dir = "./interim_data"  # Directory for interim data

# LLM Configuration
[llm]
#provider = "anthropic"  # LLM provider (openai, anthropic, etc.)
#model = "claude-3-5-haiku-latest"  # Model to use
provider = "gemini"  # LLM provider (openai, anthropic, etc.)
model = "gemini-2.0-flash"  # Model to use
# api_key = ""  # API key (if not set, will look for environment variable OPENAI_API_KEY)
max_tokens = 4096  # Maximum tokens for completions
temperature = 0.7  # Temperature for completions (0.0-1.0)
fallback_providers = ["openai"]  # Providers to try if primary fails
fallback_models = { "openai" = "o3-mini" }  # Models for fallback providers
retry_attempts = 3  # Number of retry attempts
timeout = 60  # Timeout in seconds for LLM requests

# Processing Configuration
[processing]
spacy_model = "en_core_web_lg"  # spaCy model to use
batch_size = 10  # Batch size for processing
max_chunk_size = 1000  # Maximum chunk size for text processing
min_entity_occurrences = 3  # Minimum occurrences for entity to be considered
cache_dir = "~/.cache/epub-character-graph"  # Cache directory for LLM responses
use_cache = true  # Whether to use caching
parallel_requests = 5  # Number of parallel LLM requests
extract_relationships = true  # Whether to extract character relationships
extract_groups = true  # Whether to extract character groups/factions
use_llm_for_nlp = true  # Whether to use LLM for initial NLP entity extraction
all_character_relationships = true  # Extract relationships between all characters, not just major ones
track_metrics = true  # Track additional metrics like mention counts and centrality scores
store_raw_metrics = true  # Store raw metrics in output JSON
track_character_evolution = true  # Track character evolution throughout the narrative
comprehensive_analysis = true  # Perform comprehensive character analysis including dialogue, motivations, and emotions
store_intermediate_outputs = true  # Store intermediate processing outputs like character excerpts and LLM responses

# Excerpt limits for different character types
[processing.excerpt_limits]
major_character = 50  # Excerpt limit for major characters
supporting_character = 25  # Excerpt limit for supporting characters
minor_character = 10  # Excerpt limit for minor characters
relationship = 15  # Excerpt limit for character relationships

# Output Configuration
[output]
mode = "image-prompts"  # Output mode (image-prompts or kodict)
# output_file = "characters.txt"  # Output file path (optional, defaults to EPUB filename + suffix)
template_dir = "./templates"  # Directory containing Jinja2 templates
include_minor_characters = true  # Whether to include minor characters in output
image_size = "1024x1024"  # Size for image prompts (e.g., 1024x1024)
image_style = "realistic"  # Style for image prompts (e.g., realistic, anime)
